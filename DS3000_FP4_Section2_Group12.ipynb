{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "osRx8CLo6ARD"
   },
   "source": [
    "<center> <h2> DS 3000 - Fall 2019</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONWPvHJl6ARF"
   },
   "source": [
    "<center> <h1> Northeastern Transportation Analysis</h1> </center>\n",
    "<center><h4>Benjamin Jacobson, Divit Koradia, Kyle Chu</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ip8rLjrw6ARF"
   },
   "source": [
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QA0PyejY6ARG"
   },
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VhLJ1Xot6ARG"
   },
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "Add your summary here (100-150 words)\n",
    "\n",
    "Provide a brief summary of your project. After reading this executive summary, your readers should have a rough understanding of what you did in this project. You can think of this summary in terms of the four sections of the report and write 1-2 sentences describing each section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2b-SS807KAC"
   },
   "source": [
    " Have you ever wondered what is the best way to get from Mission Hill to Northeastern campus and vice versa? When you’re in a rush calculating the time and cost of different transportation types can be tedious. Our goal is to find an answer to the best transportation type in terms of speed and cost. We will be looking at MBTA, Uber, and Bluebikes. We will be comparing the average time and cost it takes people to make it from Mission Hill to Northeastern and vice versa. Our datasets are pulled from the different transportation types websites. The data includes the time it takes to complete trips, so for Uber the time from pickup to drop off, Bluebikes it’s time for a rider to go from one station to another, and for MBTA Roxbury Crossing to Ruggles and Brigham Circle to Northeastern. Bluebikes and Uber also have the cost of each trip. MBTA and Bluebikes also have the option for a fixed cost ride structure where you can pay one price for the whole trip or use a monthly or yearly pass. We plan to measure from a point on campus to a point on Mission Hill. We will take into account average / estimated walking speeds from a station to the point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iP4g7zA6ARH"
   },
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boTet8OY6ARH"
   },
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-2Trmbo6ARH"
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNZem1t06ARI"
   },
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jok0VLR_6ARI"
   },
   "source": [
    "In this section, orient your readers to your project. You've already written some of these in previous deliverables. Based on your final analysis, revise your problem statement and write a concise introduction section. This section should touch upon the following points, but should be written in full paragraphs. Your writing should incorporate all of these points (and more if you like) in a coherent way. Remember that you are trying to convince your readers that this is an important problem to tackle. \n",
    "\n",
    "Problem Statement\n",
    "* Describe the problem you would like to tackle.   \n",
    "* What is the topic of your project? \n",
    "* What do you want to learn about it?    \n",
    "    - We want to find the best transportation method between Northeastern and Mission Hill. Lots of students live off campus near mission hill, so we'd like to help them get to campus more effectively. \n",
    "    - Transportation between two points, based on personal preferences. \n",
    "    - Depending on the person, which mode of transportation would be the most effective for them to get to campus. \n",
    "\n",
    "\n",
    "Significance of the Problem\n",
    "* Why is it important to tackle this problem in your project?\n",
    "* In what ways could the insights from this project be useful?\n",
    "* Has there been previous work on your topic? Do some research into your topic. Cite your sources appropriately. You can use the numbered reference format or APA (if you are more comfortable with it).\n",
    "\n",
    "     - It's important for us to find the best mode of transportation for each individual person as Northeastern has a very large demographic of students living/commuting to and from Mission Hill. Based on how prospective users value time, money, distance, and wait-time, we'd like to show which mode of transportation would be best fit. There hasn't been previous work on our topic. The most similar reasearch has been in estimating prices in Boston, but not choosing optimal modes of transportation. \n",
    "     - \n",
    "\n",
    "Questions/Hypothesis\n",
    "* End this section with a list of questions and hypotheses\n",
    "* You should tie these questions/hypotheses to the problem statement and its significance\n",
    "    * e.g. Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "    \n",
    "    \n",
    "    Which mode of transportation is best:\n",
    "    Which mode of transportation has the lowest average wait time for rides?\n",
    "    Which mode of transportation has the lowest average trip time from point A to point B?\n",
    "    Which mode of transportation has the least amount of walking on average?\n",
    "    Which mode of transportation has the lowest average cost?\n",
    "\n",
    "    \n",
    "    H0: MBTA >= Uber and Bluebikes\n",
    "    H1: MBTA < Uber and Bluebikes\n",
    "    The average cost for a trip will be lowest for MBTA and highest for Uber(Cost / Distance, Cost / Time) \n",
    "\n",
    "    H0: Bluebikes >= MBTA and Bluebikes\n",
    "    H1: Bluebikes < MBTA and Bluebikes\n",
    "    Average total commute time will be lowest for Bluebike and highest for MBTA\n",
    "\n",
    "    H0: Uber >= MBTA and Bluebikes\n",
    "    H1: Uber < MBTA and Bluebikes\n",
    "    Average walking time will be lowest for Uber and highest for MBTA\n",
    "\n",
    "    H0: Bluebikes >= MBTA and Uber\n",
    "    H1: Bluebikes < MBTA and Uber\n",
    "    Average wait time will be lowest for Bluebikes and highest for MBTA\n",
    "\n",
    "\n",
    "**Requirement:**\n",
    "* You should have at least one question tapping into the comparison of various machine learning algorithms in predicting your target variable from your features variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JGgr0ZW6ARJ"
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8z7TxRur6ARJ"
   },
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_OPQa0I6ARK"
   },
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "* Describe where you obtained your data. Provide a link to the original source. \n",
    "* If you scraped your data, include your code as a script file.\n",
    "* Your data should be stored in an online repository (e.g., GitHub) and your code should retrieve your data from that online resource. You can read csv files from the Web in the same way that you read files from local drive.\n",
    "* Describe the dataset and variables. What do variables represent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.ctps.org/apps/mbtasurvey2018/#navButton\n",
    "    \n",
    "    \n",
    "https://www.bluebikes.com/system-data\n",
    "    \n",
    "https://movement.uber.com/explore/boston/travel-times/query?si=302&ti=1118&ag=censustracts&dt[tpb]=ALL_DAY&dt[wd;]=1,2,3,4,5,6,7&dt[dr][sd]=2019-06-01&dt[dr][ed]=2019-06-30&cd=&sa;=-71.0908821,42.3391989&sdn=Northeastern%20University%20School%20of%20Law,%20416%20Huntington%20Ave,%20Boston,%20MA&lng.=-71.2121505&lat.=42.3599474&z.=11.49&ta;=-71.0993596,42.3330516&tdn=Mission%20Hill%20Playground,%20Boston,%20MA&lang=en-US\n",
    "#NEU to Mission Hill\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBu9v-HN6ARK"
   },
   "source": [
    "### 2.2. Variables\n",
    "* If you are testing hypotheses, what are your IVs and DVs?\n",
    "* For your predictive models, what are your features and target variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oa6QpNR6ARL"
   },
   "source": [
    "### 2.3. Data Analysis\n",
    "* Specifically describe your predictive model. What outcome variable are you going to predict from what feature variables?\n",
    "* Describe whether this is a supervised or unsupervised learning problem. Also identify the sub-category of the learning task (e.g. classification).\n",
    "* What machine learning algorithms are you going to use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZC6qAG3F6ARL"
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwYXVK-O6ARL"
   },
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfTrIL8-6ARM"
   },
   "source": [
    "### 3.1. Data Wrangling\n",
    "* Perform simple data cleaning (delete extra columns, deal with NA values, etc.)\n",
    "* Perform data wrangling to extract your features and target values (e.g., grouping your dataframe by columns, applying functions to format dataframes, etc.)\n",
    "* Preprocess your variables (e.g., scaling/transforming feature variables to normalize them)\n",
    "* Feature extraction (dummy variables, new features from existing features, etc.)\n",
    "* Use one feature selection technique to select a subset of your original features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e0ad3557e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m df_from_each_file = (pd.read_csv(f, \n\u001b[1;32m     11\u001b[0m                                  usecols=['tripduration','start station id','start station name','start station latitude','start station longitude', 'end station id','end station name','end station latitude','end station longitude'] ) for f in all_files)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mconcatenated_df\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_from_each_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mconcatenated_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start station id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'end station id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mroxbury_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenated_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'start station id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end station id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import glob \n",
    "import os\n",
    "\n",
    "# This was the code we used to clean the Bluebikes dataset and combine them into one csv. It won't run because we \n",
    "# didn't upload all the original Bluebikes excel files. Instead we uploaded the result of this code\n",
    "\n",
    "path = r'C:\\Users\\dbk29\\Downloads' # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f, \n",
    "                                 usecols=['tripduration','start station id','start station name','start station latitude','start station longitude', 'end station id','end station name','end station latitude','end station longitude'] ) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "concatenated_df.set_index(['start station id','end station id'], inplace=True)\n",
    "roxbury_data = concatenated_df.xs([27, 12], level = ['start station id', 'end station id'])\n",
    "brigham_data = concatenated_df.xs([30, 12], level = ['start station id', 'end station id'])\n",
    "blue_bikes = pd.concat([roxbury_data, brigham_data])\n",
    "blue_bikes.reset_index(inplace=True)\n",
    "blue_bikes.to_csv(\"blue_bikes_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Trip Seconds</th>\n      <th>Trip Miles</th>\n      <th>Pickup Community Area</th>\n      <th>Dropoff Community Area</th>\n      <th>Fare</th>\n      <th>target</th>\n      <th>Additional Charges</th>\n      <th>Trip Total</th>\n      <th>Shared Trip Authorized</th>\n      <th>Trips Pooled</th>\n      <th>Trip Start Day</th>\n      <th>Trip End Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>248</td>\n      <td>0.746336</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>2.55</td>\n      <td>5.05</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Tuesday</td>\n      <td>Tuesday</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>900</td>\n      <td>5.371249</td>\n      <td>8.0</td>\n      <td>22.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.72</td>\n      <td>5.72</td>\n      <td>True</td>\n      <td>2</td>\n      <td>Thursday</td>\n      <td>Thursday</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1009</td>\n      <td>5.669338</td>\n      <td>33.0</td>\n      <td>24.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>2.55</td>\n      <td>7.55</td>\n      <td>True</td>\n      <td>4</td>\n      <td>Tuesday</td>\n      <td>Tuesday</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>733</td>\n      <td>6.879594</td>\n      <td>76.0</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>9.52</td>\n      <td>19.52</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Thursday</td>\n      <td>Thursday</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>675</td>\n      <td>3.251938</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>10.00</td>\n      <td>True</td>\n      <td>1</td>\n      <td>Friday</td>\n      <td>Friday</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Trip Seconds  Trip Miles  Pickup Community Area  Dropoff Community Area  \\\n0          248    0.746336                    3.0                     3.0   \n1          900    5.371249                    8.0                    22.0   \n2         1009    5.669338                   33.0                    24.0   \n3          733    6.879594                   76.0                     NaN   \n4          675    3.251938                   10.0                     NaN   \n\n   Fare  target  Additional Charges  Trip Total  Shared Trip Authorized  \\\n0   2.5     0.0                2.55        5.05                   False   \n1   5.0     0.0                0.72        5.72                    True   \n2   5.0     0.0                2.55        7.55                    True   \n3  10.0     0.0                9.52       19.52                   False   \n4  10.0     0.0                0.00       10.00                    True   \n\n   Trips Pooled Trip Start Day Trip End Day  \n0             1        Tuesday      Tuesday  \n1             2       Thursday     Thursday  \n2             4        Tuesday      Tuesday  \n3             1       Thursday     Thursday  \n4             1         Friday       Friday  "
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "import calendar\n",
    "def change_date_weekday(date_string):\n",
    "    date_ar = date_string.split('/')\n",
    "    return calendar.day_name[date(int(date_ar[2].split(' ')[0]), int(date_ar[0]), int(date_ar[1])).weekday()] \n",
    "\n",
    "uber_tips_ds = data_sets['uber_tips'].rename(columns={'Tip': 'target'}).drop(['Pickup Centroid Location', 'Dropoff Centroid Location'], axis=1)\n",
    "uber_tips_ds['Trip Start Day'] = uber_tips_ds['Trip Start Timestamp'].apply(change_date_weekday)\n",
    "uber_tips_ds['Trip End Day'] = uber_tips_ds['Trip End Timestamp'].apply(change_date_weekday)\n",
    "uber_tips_ds['Trip Seconds'] = uber_tips_ds['Trip Seconds'].apply(lambda x:  x.replace(',', '') if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "uber_tips_ds = uber_tips_ds.drop(['Trip Start Timestamp', 'Trip End Timestamp'], axis=1)\n",
    "\n",
    "uber_tips_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sl0nr0LY6ARM"
   },
   "source": [
    "### 3.2. Data Exploration\n",
    "* Generate appropriate data visualizations for your key variables identified in the previous section\n",
    "* You should have at least three visualizations (and at least two different visualization types)\n",
    "* For each visualization provide an explanation regarding the variables involved and an interpretation of the graph.\n",
    "* If you are using Plotly, insert your visualizations as images as well (upload the graph images to an online source, e.g. github, and link those in Jupyter Notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'805 Columbus Ave, Boston, MA': ('835 Colombus Avenue, Boston, MA 02120',\n  '835 Colombus Avenue, Boston, MA 02120'),\n '100 Saint Alphonsus Street, Mission Hill, Boston': ('690 Huntington Avenue, Boston, MA 02115',\n  '15 Francis Street, Boston, MA 02115'),\n '100 Fisher Avenue, Mission Hill, Boston': ('1400 Tremont St, Boston, MA 02120',\n  '1400 Tremont St, Boston, MA 02120'),\n '47 McGreevey Way, Mission Hill, Boston': ('690 Huntington Avenue, Boston, MA 02115',\n  '15 Francis Street, Boston, MA 02115'),\n '1534 Tremont St, Roxbury Crossing, MA': ('1400 Tremont St, Boston, MA 02120',\n  '1400 Tremont St, Boston, MA 02120'),\n '40 Leon Street, Fenway/Kenmore, Boston': ('835 Colombus Avenue, Boston, MA 02120',\n  '835 Colombus Avenue, Boston, MA 02120'),\n '360 Huntington Ave, Boston, MA': ('360 Huntington Ave, Boston, MA',\n  '835 Colombus Avenue, Boston, MA 02120')}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import glob \n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "data_sets = {}\n",
    "git_url = './data_sets/' #'https://media.githubusercontent.com/media/kchu14/Northeastern-Transportation-Analysis/master/data_sets/'\n",
    "data_sets['bluebikes_data_MH_NEU'] = pd.read_csv(f'{git_url}Bluebikes_Data_MH_NEU.csv')\n",
    "data_sets['bluebikes_data_NEU_MH'] = pd.read_csv(f'{git_url}Bluebikes_Data_NEU_MH.csv')\n",
    "#data_sets['uber_ids'] = pd.read_csv(f'{git_url}Uber_Data_IDs.csv')\n",
    "data_sets['uber_mh_neu'] = pd.read_csv(f'{git_url}Uber_Data_MH_NEU.csv')\n",
    "data_sets['uber_neu_mh'] = pd.read_csv(f'{git_url}Uber_Data_NEU_MH.csv')\n",
    "data_sets['uber_neu_mh_monthly'] = pd.read_csv(f'{git_url}Uber_Data_NEU_MH_Monthly.csv')\n",
    "data_sets['uber_mh_neu_monthly'] = pd.read_csv(f'{git_url}Uber_Data_MH_NEU_Monthly.csv')\n",
    "data_sets['uber_tips'] = pd.read_csv(f'{git_url}Uber_Data_Tips.csv')\n",
    "data_sets['MBTA'] = pd.read_csv(f'{git_url}MBTA_Data.csv')\n",
    "\n",
    "\n",
    "# uber_origin_NEU = [\n",
    "#     'Northeastern University Interdisciplinary Science and Engineering Complex, 805 Columbus Ave, Boston, MA',\n",
    "# 'Northeastern University, 360 Huntington Ave, Boston, MA'\n",
    "# ]\n",
    "# uber_dest_MH = ['100 Saint Alphonsus Street, Mission Hill, Boston',\n",
    "# '100 Fisher Avenue, Mission Hill, Boston',\n",
    "# '0 McGreevey Way, Mission Hill, Boston']\n",
    "# uber_origin_MH = ['Mission Hill Main Streets, 1534 Tremont St, Roxbury Crossing, MA']\n",
    "# uber_dest_NEU = ['40 Leon Street, Fenway/Kenmore, Boston',\n",
    "# '360 Huntington Avenue, Prudential / St. Botolph, Boston']\n",
    "\n",
    "uber_stop_to_closest_station = {}\n",
    "# Map of Uber stops to closest T and Bluebikes stations\n",
    "# (t, bikes)\n",
    "brigham_t = '690 Huntington Avenue, Boston, MA 02115'\n",
    "brigham_bike = '15 Francis Street, Boston, MA 02115'\n",
    "ruggles_t = '835 Colombus Avenue, Boston, MA 02120'\n",
    "ruggles_bike = '835 Colombus Avenue, Boston, MA 02120'\n",
    "roxbury_t = '1400 Tremont St, Boston, MA 02120'\n",
    "roxbury_bike = '1400 Tremont St, Boston, MA 02120'\n",
    "northeastern_t = '360 Huntington Ave, Boston, MA'\n",
    "uber_stop_to_closest_station['805 Columbus Ave, Boston, MA'] = (ruggles_t, ruggles_bike)\n",
    "uber_stop_to_closest_station['100 Saint Alphonsus Street, Mission Hill, Boston'] = (brigham_t, brigham_bike)\n",
    "uber_stop_to_closest_station['100 Fisher Avenue, Mission Hill, Boston'] = (roxbury_t, roxbury_bike)\n",
    "uber_stop_to_closest_station['47 McGreevey Way, Mission Hill, Boston'] = (brigham_t, brigham_bike)\n",
    "uber_stop_to_closest_station['1534 Tremont St, Roxbury Crossing, MA'] = (roxbury_t, roxbury_bike) \n",
    "uber_stop_to_closest_station['40 Leon Street, Fenway/Kenmore, Boston'] = (ruggles_t, ruggles_bike)\n",
    "uber_stop_to_closest_station['360 Huntington Ave, Boston, MA'] = (northeastern_t, ruggles_bike)\n",
    "\n",
    "uber_stop_to_closest_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'805 Columbus Ave, Boston, MA': ('00:02:17', '00:02:17'),\n",
       " '100 Saint Alphonsus Street, Mission Hill, Boston': ('00:05:40', '00:07:29'),\n",
       " '100 Fisher Avenue, Mission Hill, Boston': ('00:16:16', '00:16:16'),\n",
       " '47 McGreevey Way, Mission Hill, Boston': ('00:07:08', '00:11:25'),\n",
       " '1534 Tremont St, Roxbury Crossing, MA': ('00:06:01', '00:06:01'),\n",
       " '40 Leon Street, Fenway/Kenmore, Boston': ('00:07:17', '00:07:17'),\n",
       " '360 Huntington Ave, Boston, MA': ('00:00:00', '00:08:02')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_quest_api_url = 'http://www.mapquestapi.com/directions/v2/route'\n",
    "api_key = 'siAvMEuUie853rP4T1v1Vuyfu3ndxR89'\n",
    "walking_times = {}\n",
    "\n",
    "for key, value in uber_stop_to_closest_station.items():\n",
    "    PARAMS = {'key':api_key,'routeType':'pedestrian', 'from': key, 'to': value[0]} \n",
    "    r = requests.get(url = map_quest_api_url, params = PARAMS) \n",
    "    data1 = r.json() \n",
    "    time.sleep(.5)\n",
    "    PARAMS = {'key':api_key,'routeType':'pedestrian', 'from': key, 'to': value[1]} \n",
    "    r = requests.get(url = map_quest_api_url, params = PARAMS) \n",
    "    data2 = r.json() \n",
    "#     print(f'Time it takes to walk from {key} to {value[0]} is {data1[\"route\"][\"formattedTime\"]}')\n",
    "#     print(f'Time it takes to walk from {key} to {value[1]} is {data2[\"route\"][\"formattedTime\"]}')\n",
    "    walking_times[key] = (data1[\"route\"][\"formattedTime\"],  data2[\"route\"][\"formattedTime\"])\n",
    "    \n",
    "walking_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'835 Colombus Avenue, Boston, MA 02120 - 1400 Tremont St, Boston, MA 02120': 313.9508408796895,\n",
       " '835 Colombus Avenue, Boston, MA 02120 - 15 Francis Street, Boston, MA 02115': 516.3309352517986,\n",
       " '1400 Tremont St, Boston, MA 02120 - 835 Colombus Avenue, Boston, MA 02120': 342.1673346693387,\n",
       " '15 Francis Street, Boston, MA 02115 - 835 Colombus Avenue, Boston, MA 02120': 660.5757575757576}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bluebikes average times\n",
    "\n",
    "# get the average time from station to station\n",
    "bluebike_avg_times = {}\n",
    "group_by_start_NEU_MH = pd.DataFrame(data_sets['bluebikes_data_NEU_MH'].groupby(['start station name', 'end station name']).mean()['tripduration'])\n",
    "group_by_start_MH_NEU = pd.DataFrame(data_sets['bluebikes_data_MH_NEU'].groupby(['start station name', 'end station name']).mean()['tripduration'])\n",
    "# From - To\n",
    "\n",
    "\n",
    "bluebike_avg_times[' - '.join(group_by_start_NEU_MH.index[0])] = group_by_start_NEU_MH.iloc[0]['tripduration']\n",
    "bluebike_avg_times[' - '.join(group_by_start_NEU_MH.index[1])] = group_by_start_NEU_MH.iloc[1]['tripduration']\n",
    "bluebike_avg_times[' - '.join(group_by_start_MH_NEU.index[0])] = group_by_start_MH_NEU.iloc[0]['tripduration']\n",
    "bluebike_avg_times[' - '.join(group_by_start_MH_NEU.index[1])] = group_by_start_MH_NEU.iloc[1]['tripduration']\n",
    "\n",
    "bluebike_avg_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'690 Huntington Avenue, Boston, MA 02115 - 360 Huntington Avenue, Prudential / St. Botolph, Boston': 867.6,\n",
       " '360 Huntington Avenue, Prudential / St. Botolph, Boston - 690 Huntington Avenue, Boston, MA 02115': 927.6,\n",
       " '835 Colombus Avenue, Boston, MA 02120 - 1400 Tremont St, Boston, MA 02120': 646.8,\n",
       " '1400 Tremont St, Boston, MA 02120 - 835 Colombus Avenue, Boston, MA 02120': 646.8}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MBTA average times\n",
    "\n",
    "# get the average time from station to station\n",
    "data_sets['MBTA']\n",
    "MBTA_avg_times = {}\n",
    "data_sets['MBTA']['Total Time'] = data_sets['MBTA']['Frequency'] + data_sets['MBTA']['Travel Time']\n",
    "for i in range(4):\n",
    "    MBTA_avg_times[f'{data_sets[\"MBTA\"].iloc[i][\"Start Station\"]} - {data_sets[\"MBTA\"].iloc[i][\"End Station\"]}'] = data_sets[\"MBTA\"].iloc[i][\"Total Time\"]\n",
    "                   \n",
    "MBTA_avg_times                   \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin Display Name</th>\n",
       "      <th>Destination Display Name</th>\n",
       "      <th>Date Range</th>\n",
       "      <th>Uber Mean Travel Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Origin Display Name  \\\n",
       "0    805 Columbus Ave, Boston, MA   \n",
       "1    805 Columbus Ave, Boston, MA   \n",
       "2    805 Columbus Ave, Boston, MA   \n",
       "3  360 Huntington Ave, Boston, MA   \n",
       "4  360 Huntington Ave, Boston, MA   \n",
       "\n",
       "                           Destination Display Name  \\\n",
       "0  100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "1           100 Fisher Avenue, Mission Hill, Boston   \n",
       "2            47 McGreevey Way, Mission Hill, Boston   \n",
       "3  100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "4           100 Fisher Avenue, Mission Hill, Boston   \n",
       "\n",
       "                                         Date Range  Uber Mean Travel Time  \n",
       "0  9/11/2018 - 11/10/2018, Every day, Daily Average                    296  \n",
       "1  9/11/2018 - 11/10/2018, Every day, Daily Average                    444  \n",
       "2  9/11/2018 - 11/10/2018, Every day, Daily Average                    207  \n",
       "3  9/11/2018 - 11/10/2018, Every day, Daily Average                    305  \n",
       "4  9/11/2018 - 11/10/2018, Every day, Daily Average                    472  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total times\n",
    "neu_mh = data_sets['uber_neu_mh_monthly'].copy().drop(['Origin Movement ID', 'Destination Movement ID', 'Range - Lower Bound Travel Time (Seconds)', 'Range - Upper Bound Travel Time (Seconds)'], axis=1)\n",
    "mh_neu = data_sets['uber_mh_neu_monthly'].copy().drop(['Origin Movement ID', 'Destination Movement ID', 'Range - Lower Bound Travel Time (Seconds)', 'Range - Upper Bound Travel Time (Seconds)'], axis=1)\n",
    "\n",
    "neu_mh.rename(columns={'Mean Travel Time (Seconds)': 'Uber Mean Travel Time'}, inplace = True)\n",
    "mh_neu.rename(columns={'Mean Travel Time (Seconds)': 'Uber Mean Travel Time'}, inplace = True)\n",
    "\n",
    "neu_mh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534 Tremont St, Roxbury Crossing, MA\n",
      "40 Leon Street, Fenway/Kenmore, Boston\n",
      "1534 Tremont St, Roxbury Crossing, MA--40 Leon Street, Fenway/Kenmore, Boston 1444.8\n",
      "1534 Tremont St, Roxbury Crossing, MA\n",
      "360 Huntington Avenue, Prudential / St. Botolph, Boston\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'360 Huntington Avenue, Prudential / St. Botolph, Boston'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b4cb39410f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwalking_from_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalking_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mwalking_from_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalking_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mclosest_mbta_start_station\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muber_stop_to_closest_station\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mclosest_mbta_end_station\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muber_stop_to_closest_station\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '360 Huntington Avenue, Prudential / St. Botolph, Boston'"
     ]
    }
   ],
   "source": [
    "mbta_time_neu_mh = []\n",
    "for index, row in mh_neu.iterrows():\n",
    "    start_stop = row['Origin Display Name']\n",
    "    print(start_stop)\n",
    "    end_stop = row['Destination Display Name']\n",
    "    print(end_stop)\n",
    "    walking_from_start = walking_times[start_stop][0]\n",
    "    walking_from_end = walking_times[end_stop][0]\n",
    "    closest_mbta_start_station = uber_stop_to_closest_station[start_stop][0]\n",
    "    closest_mbta_end_station = uber_stop_to_closest_station[end_stop][0]\n",
    "    string = closest_mbta_start_station + \" - \" + closest_mbta_end_station\n",
    "    travel_time = MBTA_avg_times[string]\n",
    "    walking_time_from_start = sum(x * int(t) for x, t in zip([3600, 60, 1], walking_from_start.split(\":\"))) \n",
    "    walking_time_from_end = sum(x * int(t) for x, t in zip([3600, 60, 1], walking_from_end.split(\":\")))\n",
    "    total_time = float(travel_time) + float(walking_time_from_start) + float(walking_time_from_end)\n",
    "    mbta_time_neu_mh.append(total_time)\n",
    "    print(start_stop+ '--' + end_stop + ' ' + str(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805 Columbus Ave, Boston, MA--100 Saint Alphonsus Street, Mission Hill, Boston 1102.3309352517986\n",
      "805 Columbus Ave, Boston, MA--100 Fisher Avenue, Mission Hill, Boston 1426.9508408796896\n",
      "805 Columbus Ave, Boston, MA--47 McGreevey Way, Mission Hill, Boston 1338.3309352517986\n",
      "360 Huntington Ave, Boston, MA--100 Saint Alphonsus Street, Mission Hill, Boston 1447.3309352517986\n",
      "360 Huntington Ave, Boston, MA--100 Fisher Avenue, Mission Hill, Boston 1771.9508408796896\n",
      "360 Huntington Ave, Boston, MA--47 McGreevey Way, Mission Hill, Boston 1683.3309352517986\n",
      "360 Huntington Ave, Boston, MA--100 Saint Alphonsus Street, Mission Hill, Boston 1447.3309352517986\n",
      "360 Huntington Ave, Boston, MA--100 Fisher Avenue, Mission Hill, Boston 1771.9508408796896\n",
      "360 Huntington Ave, Boston, MA--47 McGreevey Way, Mission Hill, Boston 1683.3309352517986\n",
      "805 Columbus Ave, Boston, MA--100 Saint Alphonsus Street, Mission Hill, Boston 1102.3309352517986\n",
      "805 Columbus Ave, Boston, MA--100 Fisher Avenue, Mission Hill, Boston 1426.9508408796896\n",
      "805 Columbus Ave, Boston, MA--47 McGreevey Way, Mission Hill, Boston 1338.3309352517986\n",
      "805 Columbus Ave, Boston, MA--100 Saint Alphonsus Street, Mission Hill, Boston 1102.3309352517986\n",
      "805 Columbus Ave, Boston, MA--100 Fisher Avenue, Mission Hill, Boston 1426.9508408796896\n",
      "805 Columbus Ave, Boston, MA--47 McGreevey Way, Mission Hill, Boston 1338.3309352517986\n",
      "360 Huntington Ave, Boston, MA--100 Saint Alphonsus Street, Mission Hill, Boston 1447.3309352517986\n",
      "360 Huntington Ave, Boston, MA--100 Fisher Avenue, Mission Hill, Boston 1771.9508408796896\n",
      "360 Huntington Ave, Boston, MA--47 McGreevey Way, Mission Hill, Boston 1683.3309352517986\n"
     ]
    }
   ],
   "source": [
    "bluebike_time = []\n",
    "for index, row in neu_mh.iterrows():\n",
    "    start_stop = row['Origin Display Name']\n",
    "    #print(start_stop)\n",
    "    end_stop = row['Destination Display Name']\n",
    "    walking_from_start = walking_times[start_stop][1]\n",
    "    walking_from_end = walking_times[end_stop][1]\n",
    "    closest_bike_start_station = uber_stop_to_closest_station[start_stop][1]\n",
    "    closest_bike_end_station = uber_stop_to_closest_station[end_stop][1]\n",
    "    string = closest_bike_start_station + \" - \" + closest_bike_end_station\n",
    "    travel_time = bluebike_avg_times[string]\n",
    "    walking_time_from_start = sum(x * int(t) for x, t in zip([3600, 60, 1], walking_from_start.split(\":\"))) \n",
    "    walking_time_from_end = sum(x * int(t) for x, t in zip([3600, 60, 1], walking_from_end.split(\":\")))\n",
    "    total_time = float(travel_time) + float(walking_time_from_start) + float(walking_time_from_end)\n",
    "    bluebike_time.append(total_time)\n",
    "    print(start_stop+ '--' + end_stop + ' ' + str(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin Display Name</th>\n",
       "      <th>Destination Display Name</th>\n",
       "      <th>Date Range</th>\n",
       "      <th>Uber Mean Travel Time</th>\n",
       "      <th>Blue Bike Average Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>296</td>\n",
       "      <td>1102.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>444</td>\n",
       "      <td>1426.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>207</td>\n",
       "      <td>1338.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>305</td>\n",
       "      <td>1447.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>472</td>\n",
       "      <td>1771.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>9/11/2018 - 11/10/2018, Every day, Daily Average</td>\n",
       "      <td>196</td>\n",
       "      <td>1683.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>11/11/2018 - 2/9/2019, Every day, Midday</td>\n",
       "      <td>290</td>\n",
       "      <td>1447.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>11/11/2018 - 2/9/2019, Every day, Midday</td>\n",
       "      <td>471</td>\n",
       "      <td>1771.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>11/11/2018 - 2/9/2019, Every day, Midday</td>\n",
       "      <td>189</td>\n",
       "      <td>1683.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>11/11/2018 - 2/9/2019, Every day, Midday</td>\n",
       "      <td>286</td>\n",
       "      <td>1102.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>11/11/2018 - 2/9/2019, Every day, Midday</td>\n",
       "      <td>448</td>\n",
       "      <td>1426.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>11/11/2018 - 2/9/2019, Every day, Midday</td>\n",
       "      <td>193</td>\n",
       "      <td>1338.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>2/10/2019 - 5/3/2019, Every day, Midday</td>\n",
       "      <td>301</td>\n",
       "      <td>1102.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>2/10/2019 - 5/3/2019, Every day, Midday</td>\n",
       "      <td>461</td>\n",
       "      <td>1426.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>805 Columbus Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>2/10/2019 - 5/3/2019, Every day, Midday</td>\n",
       "      <td>214</td>\n",
       "      <td>1338.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Saint Alphonsus Street, Mission Hill, Boston</td>\n",
       "      <td>2/10/2019 - 5/3/2019, Every day, Midday</td>\n",
       "      <td>319</td>\n",
       "      <td>1447.330935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>100 Fisher Avenue, Mission Hill, Boston</td>\n",
       "      <td>2/10/2019 - 5/3/2019, Every day, Midday</td>\n",
       "      <td>515</td>\n",
       "      <td>1771.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>360 Huntington Ave, Boston, MA</td>\n",
       "      <td>47 McGreevey Way, Mission Hill, Boston</td>\n",
       "      <td>2/10/2019 - 5/3/2019, Every day, Midday</td>\n",
       "      <td>208</td>\n",
       "      <td>1683.330935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Origin Display Name  \\\n",
       "0     805 Columbus Ave, Boston, MA   \n",
       "1     805 Columbus Ave, Boston, MA   \n",
       "2     805 Columbus Ave, Boston, MA   \n",
       "3   360 Huntington Ave, Boston, MA   \n",
       "4   360 Huntington Ave, Boston, MA   \n",
       "5   360 Huntington Ave, Boston, MA   \n",
       "6   360 Huntington Ave, Boston, MA   \n",
       "7   360 Huntington Ave, Boston, MA   \n",
       "8   360 Huntington Ave, Boston, MA   \n",
       "9     805 Columbus Ave, Boston, MA   \n",
       "10    805 Columbus Ave, Boston, MA   \n",
       "11    805 Columbus Ave, Boston, MA   \n",
       "12    805 Columbus Ave, Boston, MA   \n",
       "13    805 Columbus Ave, Boston, MA   \n",
       "14    805 Columbus Ave, Boston, MA   \n",
       "15  360 Huntington Ave, Boston, MA   \n",
       "16  360 Huntington Ave, Boston, MA   \n",
       "17  360 Huntington Ave, Boston, MA   \n",
       "\n",
       "                            Destination Display Name  \\\n",
       "0   100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "1            100 Fisher Avenue, Mission Hill, Boston   \n",
       "2             47 McGreevey Way, Mission Hill, Boston   \n",
       "3   100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "4            100 Fisher Avenue, Mission Hill, Boston   \n",
       "5             47 McGreevey Way, Mission Hill, Boston   \n",
       "6   100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "7            100 Fisher Avenue, Mission Hill, Boston   \n",
       "8             47 McGreevey Way, Mission Hill, Boston   \n",
       "9   100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "10           100 Fisher Avenue, Mission Hill, Boston   \n",
       "11            47 McGreevey Way, Mission Hill, Boston   \n",
       "12  100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "13           100 Fisher Avenue, Mission Hill, Boston   \n",
       "14            47 McGreevey Way, Mission Hill, Boston   \n",
       "15  100 Saint Alphonsus Street, Mission Hill, Boston   \n",
       "16           100 Fisher Avenue, Mission Hill, Boston   \n",
       "17            47 McGreevey Way, Mission Hill, Boston   \n",
       "\n",
       "                                          Date Range  Uber Mean Travel Time  \\\n",
       "0   9/11/2018 - 11/10/2018, Every day, Daily Average                    296   \n",
       "1   9/11/2018 - 11/10/2018, Every day, Daily Average                    444   \n",
       "2   9/11/2018 - 11/10/2018, Every day, Daily Average                    207   \n",
       "3   9/11/2018 - 11/10/2018, Every day, Daily Average                    305   \n",
       "4   9/11/2018 - 11/10/2018, Every day, Daily Average                    472   \n",
       "5   9/11/2018 - 11/10/2018, Every day, Daily Average                    196   \n",
       "6           11/11/2018 - 2/9/2019, Every day, Midday                    290   \n",
       "7           11/11/2018 - 2/9/2019, Every day, Midday                    471   \n",
       "8           11/11/2018 - 2/9/2019, Every day, Midday                    189   \n",
       "9           11/11/2018 - 2/9/2019, Every day, Midday                    286   \n",
       "10          11/11/2018 - 2/9/2019, Every day, Midday                    448   \n",
       "11          11/11/2018 - 2/9/2019, Every day, Midday                    193   \n",
       "12           2/10/2019 - 5/3/2019, Every day, Midday                    301   \n",
       "13           2/10/2019 - 5/3/2019, Every day, Midday                    461   \n",
       "14           2/10/2019 - 5/3/2019, Every day, Midday                    214   \n",
       "15           2/10/2019 - 5/3/2019, Every day, Midday                    319   \n",
       "16           2/10/2019 - 5/3/2019, Every day, Midday                    515   \n",
       "17           2/10/2019 - 5/3/2019, Every day, Midday                    208   \n",
       "\n",
       "    Blue Bike Average Time  \n",
       "0              1102.330935  \n",
       "1              1426.950841  \n",
       "2              1338.330935  \n",
       "3              1447.330935  \n",
       "4              1771.950841  \n",
       "5              1683.330935  \n",
       "6              1447.330935  \n",
       "7              1771.950841  \n",
       "8              1683.330935  \n",
       "9              1102.330935  \n",
       "10             1426.950841  \n",
       "11             1338.330935  \n",
       "12             1102.330935  \n",
       "13             1426.950841  \n",
       "14             1338.330935  \n",
       "15             1447.330935  \n",
       "16             1771.950841  \n",
       "17             1683.330935  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_mh['Blue Bike Average Time'] = bluebike_time\n",
    "neu_mh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mh_neu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bdb4f3806d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbluebike_time_mh_neu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmh_neu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstart_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Origin Display Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mend_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Destination Display Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mh_neu' is not defined"
     ]
    }
   ],
   "source": [
    "bluebike_time_mh_neu = []\n",
    "for index, row in mh_neu.iterrows():\n",
    "    start_stop = row['Origin Display Name']\n",
    "    print(start_stop)\n",
    "    end_stop = row['Destination Display Name']\n",
    "    print(end_stop)\n",
    "    walking_from_start = walking_times[start_stop][1]\n",
    "    walking_from_end = walking_times[end_stop][1]\n",
    "    closest_bike_start_station = uber_stop_to_closest_station[start_stop][1]\n",
    "    closest_bike_end_station = uber_stop_to_closest_station[end_stop][1]\n",
    "    string = closest_bike_start_station + \" - \" + closest_bike_end_station\n",
    "    travel_time = bluebike_avg_times[string]\n",
    "    walking_time_from_start = sum(x * int(t) for x, t in zip([3600, 60, 1], walking_from_start.split(\":\"))) \n",
    "    walking_time_from_end = sum(x * int(t) for x, t in zip([3600, 60, 1], walking_from_end.split(\":\")))\n",
    "    total_time = float(travel_time) + float(walking_time_from_start) + float(walking_time_from_end)\n",
    "    bluebike_time_mh_neu.append(total_time)\n",
    "    print(start_stop+ '--' + end_stop + ' ' + str(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXg4vfc76ARN"
   },
   "source": [
    "### 3.3. Model Construction\n",
    "* If you proposed hypotheses, conduct your hypothesis tests\n",
    "* For your machine learning question(s), split data into training, validation, and testing sets (or use cross-validation)\n",
    "* Apply machine learning algorithms (apply at least three algorithms)\n",
    "* Train your algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_target(df):\n",
    "      return df.drop(\"target\", axis = 1), df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = features_and_target(uber_tips_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_the_dataset():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)  \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_the_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1,339'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-304cd2563e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m estimators = {\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m'LinearRegression'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m'Ridge'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m'Lasso'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 463\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1,339'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "estimators = {\n",
    "    'LinearRegression': LinearRegression().fit(X=X_train, y=y_train), \n",
    "    'Ridge': Ridge().fit(X=X_train, y=y_train),\n",
    "    'Lasso': Lasso().fit(X=X_train, y=y_train),\n",
    "    'KNeighborsRegressor':  KNeighborsRegressor().fit(X=X_train, y=y_train),\n",
    "    'SVR': SVR(gamma='scale', C=1).fit(X=X_train, y=y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressors_percentage_split():\n",
    "    for key, value in estimators.items():\n",
    "        print(key)\n",
    "        print(\"    R-squared value for training set: \", r2_score(y_train, value.predict(X_train)))\n",
    "        print(\"    R-squared value for testing set: \", r2_score(y_test, value.predict(X_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocessed_regression():\n",
    "    \n",
    "\n",
    "    #create the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    #fit the scaler to the training data(features only)\n",
    "    scaler.fit(X_train) \n",
    "\n",
    "    #transform X_train and X_test based on the (same) scaler\n",
    "    X_train_scaled = scaler.transform(X_train) \n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "    for key, value in estimators.items():\n",
    "        print(key)\n",
    "        \n",
    "        if 'Linear' in key:\n",
    "            model = LinearRegression().fit(X=X_train_scaled, y=y_train)\n",
    "        if 'Ridge' in key:\n",
    "            model = Ridge().fit(X=X_train_scaled, y=y_train)\n",
    "        if 'Lasso' in key:\n",
    "            model = Lasso().fit(X=X_train_scaled, y=y_train)\n",
    "        if 'KNeighborsRegressor' in key:\n",
    "            model = KNeighborsRegressor().fit(X=X_train_scaled, y=y_train)\n",
    "        if 'SVR' in key:\n",
    "            model = SVR(gamma='scale', C=1).fit(X=X_train_scaled, y=y_train)\n",
    "\n",
    "        print(\"    R^2 for training set: \", r2_score(y_train, model.predict(X_train_scaled)))\n",
    "        print(\"    R^2 for testing set: \", r2_score(y_test, model.predict(X_test_scaled)))\n",
    "    return X_train_scaled, X_test_scaled \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = preprocessed_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def RFE_feature_selection():\n",
    "    select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 3)\n",
    "    #fit the RFE selector to the training data\n",
    "    select.fit(X_train, y_train)\n",
    "\n",
    "    #transform training and testing sets so only the selected features are retained\n",
    "    X_train_selected = select.transform(X_train_scaled)\n",
    "    X_test_selected = select.transform(X_test_scaled)\n",
    "    model = KNeighborsRegressor().fit(X=X_train_selected, y=y_train)\n",
    "    print('Selected features after RFE:')\n",
    "    features_bool = np.array(select.support_)\n",
    "    cols = np.array(features.columns)\n",
    "    result = cols[features_bool]\n",
    "    [print(\"   \", i) for i in result ]\n",
    " \n",
    "    print(\"kNN Regression performance with selected features:\")\n",
    "    print(\"\\tR-squared value for training set: \", r2_score(y_train, model.predict(X_train_selected)))\n",
    "    print(\"\\tR-squared value for testing set: \", r2_score(y_test, model.predict(X_test_selected)))\n",
    "    return X_train_selected, X_test_selected\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '4/26/2019 22:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-238afea479c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE_feature_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-2e8d5f3978e9>\u001b[0m in \u001b[0;36mRFE_feature_selection\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#fit the RFE selector to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#transform training and testing sets so only the selected features are retained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# self.scores_ will not be calculated when calling _fit through fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '4/26/2019 22:00'"
     ]
    }
   ],
   "source": [
    "X_train_selected, X_test_selected = RFE_feature_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rzOr32Z6ARN"
   },
   "source": [
    "### 3.4. Model Evaluation\n",
    "* Evaluate the performance of your algorithms on appropriate evaluation metrics, using your validation set\n",
    "* Interpret your results from multiple models (and hypothesis tests, if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llw9GTFU6ARN"
   },
   "source": [
    "### 3.5. Model Optimization\n",
    "* Tune your models using appropriate hyperparameters\n",
    "* Explain why you are doing this (e.g., to avoid overfitting, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUFCSNaV6ARO"
   },
   "source": [
    "### 3.6. Model Testing\n",
    "* Test your tuned algorithms using your testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcY99Uxf6ARO"
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGoVDJbF6ARP"
   },
   "source": [
    "## 4. DISCUSSION\n",
    "* Provide a summary of the steps you took to analyze your data and test your predictive model\n",
    "* Intepret your findings from 3.4., 3.5, and 3.6\n",
    "    * Which algorithms did you compare?\n",
    "    * Which algorithm(s) revealed best performance?\n",
    "    * Which algorithm(s) should be used for your predictive model?\n",
    "* If you tested hypotheses, interpret the results. What does it mean to have significant/non-significant differences with regards to your data?\n",
    "\n",
    "\n",
    "* End this section with a conclusion paragraph containing some pointers for future work \n",
    "    *(e.g., get more data, perform another analysis, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Wgs5bw96ARP"
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6cy_S8w6ARQ"
   },
   "source": [
    "### CONTRIBUTIONS\n",
    "* Describe each team member's contributions to the report (who did what in each section)\n",
    "* Remember this is a team effort!\n",
    "* Each member of your team will provide peer evaluation of other team members. Your final grade on the project will be based on those peer evaluations. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS3000_FP4_Section2_Group12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}